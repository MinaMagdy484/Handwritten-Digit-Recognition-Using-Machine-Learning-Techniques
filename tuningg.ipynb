{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, mean_squared_error, r2_score\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdir = r'D:\\Fourth Year\\First Term\\Machine\\Lectures\\project\\10000'\n",
    "filepaths = []\n",
    "labels = []\n",
    "data = []\n",
    "classlist = os.listdir(sdir)\n",
    "class_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for klass in classlist:\n",
    "    classpath = os.path.join(sdir, klass)\n",
    "    flist = os.listdir(classpath)\n",
    "\n",
    "    for f in flist:\n",
    "        fpath = os.path.join(classpath, f)\n",
    "        filepaths.append(fpath)\n",
    "        labels.append(class_index)\n",
    "\n",
    "        # Process the image\n",
    "        with Image.open(fpath) as img:\n",
    "            img = img.convert('L')  # Convert to grayscale\n",
    "            img_resized = img.resize((28, 28))  # Ensure size is 28x28\n",
    "            img_array = np.array(img_resized).flatten()  # Flatten to 1D vector\n",
    "            img_array = img_array / 255.0  # Normalize to [0, 1]\n",
    "            data.append(img_array)  # Append the processed data\n",
    "\n",
    "    class_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data)  # Image data as 784 columns\n",
    "data_df['labels'] = labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.627451  0.658824  0.654902  0.627451  0.635294  0.647059  0.639216   \n",
      "1  0.549020  0.470588  0.243137  0.101961  0.211765  0.415686  0.533333   \n",
      "2  0.686275  0.682353  0.674510  0.674510  0.674510  0.674510  0.682353   \n",
      "3  0.741176  0.717647  0.741176  0.764706  0.725490  0.658824  0.650980   \n",
      "4  0.435294  0.262745  0.113725  0.286275  0.443137  0.454902  0.454902   \n",
      "\n",
      "          7         8         9  ...       775       776       777       778  \\\n",
      "0  0.635294  0.647059  0.654902  ...  0.647059  0.615686  0.607843  0.658824   \n",
      "1  0.600000  0.709804  0.678431  ...  0.678431  0.690196  0.698039  0.682353   \n",
      "2  0.682353  0.678431  0.678431  ...  0.486275  0.419608  0.517647  0.666667   \n",
      "3  0.682353  0.662745  0.690196  ...  0.498039  0.549020  0.623529  0.709804   \n",
      "4  0.450980  0.454902  0.443137  ...  0.458824  0.462745  0.466667  0.470588   \n",
      "\n",
      "        779       780       781       782       783  labels  \n",
      "0  0.686275  0.662745  0.639216  0.603922  0.635294       0  \n",
      "1  0.670588  0.678431  0.678431  0.658824  0.674510       0  \n",
      "2  0.670588  0.474510  0.486275  0.584314  0.615686       0  \n",
      "3  0.737255  0.627451  0.388235  0.129412  0.000000       0  \n",
      "4  0.470588  0.466667  0.458824  0.466667  0.478431       0  \n",
      "\n",
      "[5 rows x 785 columns]\n",
      "DataFrame length: 10000\n"
     ]
    }
   ],
   "source": [
    "print(data_df.head())  # Print the first few rows\n",
    "print('DataFrame length:', len(data_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      "0    1000\n",
      "1    1000\n",
      "2    1000\n",
      "3    1000\n",
      "4    1000\n",
      "5    1000\n",
      "6    1000\n",
      "7    1000\n",
      "8    1000\n",
      "9    1000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "balance = data_df['labels'].value_counts()\n",
    "print(balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_df.drop(columns=['labels'])\n",
    "y = data_df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Model evaluation function\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    predictions = model.predict(X_test)  # Predict on test data\n",
    "\n",
    "    if isinstance(model, LinearRegression):\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "        print(f\"R-squared: {r2:.4f}\")\n",
    "    else:\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        precision = precision_score(y_test, predictions, average='weighted', zero_division=0)\n",
    "        recall = recall_score(y_test, predictions, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, predictions, average='weighted', zero_division=0)\n",
    "        conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-Score: {f1:.4f}\")\n",
    "        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500, solver='lbfgs', multi_class='multinomial',penalty='l2'),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Linear Regression\": LinearRegression()\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning for Logistic Regression\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  # Regularization strength\n",
    "    'solver': ['lbfgs'],\n",
    "    'multi_class': ['ovr'],  # One-vs-rest strategy\n",
    "    'max_iter': [100, 200],\n",
    "    'penalty': ['l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Logistic Regression: {'C': 0.1, 'max_iter': 200, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "\n",
      "Best Logistic Regression Model:\n",
      "Accuracy: 0.7620\n",
      "Precision: 0.7619\n",
      "Recall: 0.7620\n",
      "F1-Score: 0.7610\n",
      "Confusion Matrix:\n",
      "[[162   8   0   2   7   2   7   2   4   6]\n",
      " [  5 163   5   5   2   3   1  10   6   0]\n",
      " [  4   5 150  10   6   3   1   9   3   9]\n",
      " [  8   3   7 155   9   3   0   4   7   4]\n",
      " [  5   6   3   1 154   3   8   7   6   7]\n",
      " [  7   5   3   5   2 153  11   5   8   1]\n",
      " [  0  10   1   1   1  11 172   1   3   0]\n",
      " [  1  10   9   2   6   1   3 140   5  23]\n",
      " [  9   5   4   8  13  15   7  11 123   5]\n",
      " [  7   3   5   9  10   0   0  11   3 152]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "grid_search = GridSearchCV(logistic_model, param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters for Logistic Regression:\", grid_search.best_params_)\n",
    "best_logistic_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best logistic regression model\n",
    "print(\"\\nBest Logistic Regression Model:\")\n",
    "evaluate_model(best_logistic_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7620\n",
      "Precision: 0.7619\n",
      "Recall: 0.7620\n",
      "F1-Score: 0.7610\n",
      "Confusion Matrix:\n",
      "[[162   8   0   2   7   2   7   2   4   6]\n",
      " [  5 163   5   5   2   3   1  10   6   0]\n",
      " [  4   5 150  10   6   3   1   9   3   9]\n",
      " [  8   3   7 155   9   3   0   4   7   4]\n",
      " [  5   6   3   1 154   3   8   7   6   7]\n",
      " [  7   5   3   5   2 153  11   5   8   1]\n",
      " [  0  10   1   1   1  11 172   1   3   0]\n",
      " [  1  10   9   2   6   1   3 140   5  23]\n",
      " [  9   5   4   8  13  15   7  11 123   5]\n",
      " [  7   3   5   9  10   0   0  11   3 152]]\n",
      "--------------------------------------------------\n",
      "Evaluating Naive Bayes...\n",
      "Accuracy: 0.5115\n",
      "Precision: 0.5433\n",
      "Recall: 0.5115\n",
      "F1-Score: 0.5144\n",
      "Confusion Matrix:\n",
      "[[118  26   3   8  15   7  11   2   2   8]\n",
      " [  2 133   2  19   5   5   7  20   4   3]\n",
      " [  4  40  70  42   6   1   1  11  16   9]\n",
      " [ 11  25  11 122   7   2   0   5   6  11]\n",
      " [ 18  28   8   3  86   1  10   7  23  16]\n",
      " [ 12  45   9   3   6  89  14   5  12   5]\n",
      " [ 14  38   2   2   3  13 117   4   6   1]\n",
      " [  6  35   6  12   9   2   2 100  13  15]\n",
      " [ 13  31   6  19  12  17  10   7  77   8]\n",
      " [ 12  21   6  18  10   1   0  15   6 111]]\n",
      "--------------------------------------------------\n",
      "Evaluating Linear Regression...\n",
      "Mean Squared Error: 6.4785\n",
      "R-squared: 0.2147\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    if model_name == \"Logistic Regression\":\n",
    "        evaluate_model(best_logistic_model, X_train, y_train, X_test, y_test)\n",
    "    else:\n",
    "        evaluate_model(model, X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
